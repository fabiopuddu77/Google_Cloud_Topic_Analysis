{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1557468e-5e87-4fd6-9ae1-2f29ed062854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from processing.data_preparation import GCSParquetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f8a392-5519-42bc-b3fc-f99e4bf2f9e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://ccai-storage/pipeline_root/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_ID = 'gcp-ccai-auto-ml-contactcenter'\n",
    "REGION= \"europe-west3\"\n",
    "REPO_NAME = \"repo-demo3\"\n",
    "SERVICE_ACCOUNT = \"944308723981-compute@developer.gserviceaccount.com\"\n",
    "BUCKET = \"ccai-storage\"\n",
    "PIPELINE_NAME = \"automl_pipeline\"\n",
    "YAML_NAME = f\"{PIPELINE_NAME}.yml\"\n",
    "PIPELINE_ROOT = f\"gs://{BUCKET}/pipeline_root/\"\n",
    "DISPLAY_NAME = PIPELINE_NAME.replace(\"_\", \"-\")\n",
    "NOTEBOOK = \"automl\"\n",
    "DATANAME = \"datasetnlp\"\n",
    "BQ_NAME = \"finaldf5\"\n",
    "FILE_PATH = 'articlesoutput.parquet'\n",
    "FOLDER = 'pipeline'\n",
    "PROJECT_ID = 'gcp-ccai-auto-ml-contactcenter'\n",
    "TABLE_ID = \"stepfinalbq\"\n",
    "TEXT_COLUMN = 'body_pre'\n",
    "LOCATION = \"europe-west3\"\n",
    "NUM_DOC = 10\n",
    "#BQ_SOURCE = \"bq://gcp-ccai-auto-ml-contactcenter.datasetnlp.stepfinalbq\"\n",
    "OUTPUT_PROCESSING = 'test_step1_pipeline.parquet'\n",
    "OUTPUT_TOKENIZATION = 'step2_pipeline.parquet'\n",
    "OUTPUT_SENTIMENT = 'step3_pipeline.parquet'\n",
    "OUTPUT_MODERATE = 'step4_pipeline.parquet'\n",
    "OUTPUT_ENTITIES = 'step5_pipeline.parquet'\n",
    "OUTPUT_FINAL = 'pipeline/step_final_bq.parquet'\n",
    "\n",
    "PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87451198-9915-4a01-a52a-2c6ab9d9d7b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Check if the file in exists in gcs test_step1_pipeline.parquet\n",
      "\n",
      "INFO: Start loading DataFrame from articlesoutput.parquet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if the file in exists in gcs\n",
      "Start loading DataFrame from articlesoutput.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Loaded DataFrame from articlesoutput.parquet\n",
      "\n",
      "INFO: Loading Data Preparation\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DataFrame from articlesoutput.parquet\n",
      "Loading Data Preparation\n",
      "Analyze articles\n",
      "Replace empty strings with NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/gcp-ccai-auto-ml-contactcenter/End-to-end-AutoML-Topic-Classification/Training_autoML_pipeline/custom-data-preparation-image/processing/data_preparation.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_dups.replace('', np.nan, inplace=True)\n",
      "/home/jupyter/gcp-ccai-auto-ml-contactcenter/End-to-end-AutoML-Topic-Classification/Training_autoML_pipeline/custom-data-preparation-image/processing/data_preparation.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_dups_remov.loc[:,'topic'] = df_no_dups_remov.loc[:,'categoryLabels'].str.split(';').str[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove rows where both 'title' and 'authors' are NaN\n",
      "Analyze articles\n",
      "Replace empty strings with NaN\n",
      "Remove rows where both 'title' and 'authors' are NaN\n",
      "topic                   split   \n",
      "Arts and Entertainment  TRAIN       10935\n",
      "                        TEST          288\n",
      "                        VALIDATE      288\n",
      "Business                TRAIN        7022\n",
      "                        TEST          185\n",
      "                        VALIDATE      185\n",
      "Environment             TRAIN         371\n",
      "                        TEST           10\n",
      "                        VALIDATE       10\n",
      "Health                  TRAIN        2109\n",
      "                        TEST           56\n",
      "                        VALIDATE       56\n",
      "Politics                TRAIN       10958\n",
      "                        TEST          289\n",
      "                        VALIDATE      288\n",
      "Science                 TRAIN         301\n",
      "                        TEST            8\n",
      "                        VALIDATE        8\n",
      "Sports                  TRAIN        3451\n",
      "                        TEST           91\n",
      "                        VALIDATE       91\n",
      "Technology              TRAIN        1141\n",
      "                        TEST           31\n",
      "                        VALIDATE       30\n",
      "Name: count, dtype: int64\n",
      "topic\n",
      "Arts and Entertainment    301\n",
      "Business                  301\n",
      "Environment               301\n",
      "Health                    301\n",
      "Politics                  301\n",
      "Science                   301\n",
      "Sports                    301\n",
      "Technology                301\n",
      "Name: count, dtype: int64\n",
      "split\n",
      "TRAIN       2408\n",
      "TEST         958\n",
      "VALIDATE     956\n",
      "Name: count, dtype: int64\n",
      "Dataset splitted - process completed and file saved to GCS.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Dataset preprocessed- process completed and file saved to GCS.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preprocessed - process completed and file saved to GCS.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test_step1_pipeline.parquet'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "processor=GCSParquetLoader(bucket=BUCKET, file_path=FILE_PATH, \n",
    "                               folder=FOLDER, parquet_file_name=OUTPUT_PROCESSING)\n",
    "processor.process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aedd5e6-7f08-4d80-8b49-c53669309861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m115"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

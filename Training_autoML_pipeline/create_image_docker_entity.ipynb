{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "447b18ca-84c8-4104-b629-492b47d55158",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'gcp-ccai-auto-ml-contactcenter'\n",
    "REGION= \"europe-west3\"\n",
    "REPO_NAME = \"repo-demo3\"\n",
    "SERVICE_ACCOUNT = \"944308723981-compute@developer.gserviceaccount.com\"\n",
    "BUCKET_URI = f\"gs://ccai-storage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84dfec18-3d18-4cd2-b563-9d0ef3227ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLICATION_DIR = \"custom-data-entities-image\"\n",
    "PROCESSING_DIR = f\"{APPLICATION_DIR}/processing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06844018-e1c3-45dd-8b45-9adf0fb270c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing custom-data-entities-image/Dockerfile\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'custom-data-entities-image/Dockerfile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwritefile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{APPLICATION_DIR}\u001b[39;49;00m\u001b[38;5;124;43m/Dockerfile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mFROM us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu113.py310\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mWORKDIR /\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mCOPY requirements.txt /\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Installs hypertune library\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mRUN pip install -r requirements.txt\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Copies the trainer code to the Docker image.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mCOPY processing /processing\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/magics/osm.py:854\u001b[0m, in \u001b[0;36mOSMagics.writefile\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriting \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m filename)\n\u001b[1;32m    853\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mappend \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 854\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    855\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(cell)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'custom-data-entities-image/Dockerfile'"
     ]
    }
   ],
   "source": [
    "%%writefile {APPLICATION_DIR}/Dockerfile\n",
    "\n",
    "FROM us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu113.py310\n",
    "\n",
    "WORKDIR /\n",
    "\n",
    "COPY requirements.txt /\n",
    "\n",
    "# Installs hypertune library\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "# Copies the trainer code to the Docker image.\n",
    "COPY processing /processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "efe7f0bc-bd31-41e8-8f65-36d594ef0958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.artifacts.repositories.create) ALREADY_EXISTS: the repository already exists\n"
     ]
    }
   ],
   "source": [
    "!gcloud artifacts repositories create $REPO_NAME --repository-format=docker \\\n",
    "--location=$REGION --description=\"Docker repository\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0df4ce5-e397-4230-a04a-9f20c2cc41b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGE_URI = (\n",
    "    f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPO_NAME}/data_entities:latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7cac20f0-7893-406f-85e9-f7ada569c752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'custom-data-entities-image'\n",
      "/home/jupyter/fabio/pipeline/custom-data-entities-image\n"
     ]
    }
   ],
   "source": [
    "cd $APPLICATION_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd4e3d65-f671-4353-ab77-a89e336afda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  36.35kB\n",
      "Step 1/5 : FROM us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu113.py310\n",
      " ---> 039eb2919b37\n",
      "Step 2/5 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> eb5e1d2a1fa8\n",
      "Step 3/5 : COPY requirements.txt /\n",
      " ---> Using cache\n",
      " ---> b2d930b4ff46\n",
      "Step 4/5 : RUN pip install -r requirements.txt\n",
      " ---> Using cache\n",
      " ---> 8bae61c7c46f\n",
      "Step 5/5 : COPY processing /processing\n",
      " ---> 3fa3d3b8b55f\n",
      "Successfully built 3fa3d3b8b55f\n",
      "Successfully tagged europe-west3-docker.pkg.dev/gcp-ccai-auto-ml-contactcenter/repo-demo3/data_entities:latest\n"
     ]
    }
   ],
   "source": [
    "! docker build ./ -t $IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "94fb912b-9779-430f-9d31-6b813be0f8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"europe-west3-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: europe-west3-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "! gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fdcbf116-aa8b-4d6f-a43d-b479240ecab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [europe-west3-docker.pkg.dev/gcp-ccai-auto-ml-contactcenter/repo-demo3/data_entities]\n",
      "\n",
      "\u001b[1Bf7d53bcd: Preparing \n",
      "\u001b[1Bbe4efcd5: Preparing \n",
      "\u001b[1B2531ecbd: Preparing \n",
      "\u001b[1B0840b95b: Preparing \n",
      "\u001b[1B625a528c: Preparing \n",
      "\u001b[1B1351140a: Preparing \n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1B82771da2: Preparing \n",
      "\u001b[1B57952521: Preparing \n",
      "\u001b[1B6a5b98f7: Preparing \n",
      "\u001b[1Bbd61aa20: Preparing \n",
      "\u001b[1B5ef9c8b3: Preparing \n",
      "\u001b[1Ba870a840: Preparing \n",
      "\u001b[1B43031e88: Preparing \n",
      "\u001b[1Bab4e5392: Preparing \n",
      "\u001b[1B07dc0b52: Preparing \n",
      "\u001b[1Bdcdb0172: Preparing \n",
      "\u001b[1B379a4282: Preparing \n",
      "\u001b[1Baea69765: Preparing \n",
      "\u001b[1B6aad04a1: Preparing \n",
      "\u001b[1Bdfc3b824: Preparing \n",
      "\u001b[1B4c2a35b9: Preparing \n",
      "\u001b[17Bf18a086: Waiting g \n",
      "\u001b[1B3da23f15: Preparing \n",
      "\u001b[20B351140a: Waiting g \n",
      "\u001b[1Bb784db22: Preparing \n",
      "\u001b[21Bf18a086: Preparing \n",
      "\u001b[20B7952521: Waiting g \n",
      "\u001b[1B95b7aaed: Preparing \n",
      "\u001b[1Bf5722498: Preparing \n",
      "\u001b[1B2c163a83: Preparing \n",
      "\u001b[17B7dc0b52: Waiting g \n",
      "\u001b[17Bcdb0172: Waiting g \n",
      "\u001b[25Ba5b98f7: Waiting g \n",
      "\u001b[1Ba8f43981: Preparing \n",
      "\u001b[19B79a4282: Waiting g \n",
      "\u001b[1B4a4d2337: Preparing \n",
      "\u001b[16B90090ea: Waiting g \n",
      "\u001b[16Bda23f15: Waiting g \n",
      "\u001b[1B34842944: Preparing \n",
      "\u001b[1B7df31590: Layer already exists 1kB\u001b[36A\u001b[2K\u001b[29A\u001b[2K\u001b[22A\u001b[2K\u001b[20A\u001b[2K\u001b[15A\u001b[2K\u001b[9A\u001b[2K\u001b[4A\u001b[2Klatest: digest: sha256:6bf85cedbd05614b1cc23a4000614c63e6c026c6822ed4a913cdbce9043e31fd size: 9115\n"
     ]
    }
   ],
   "source": [
    "! docker push $IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064de5a3-bf79-4919-84bb-ab24ff8654bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc83fe-5f50-4ba3-9b4c-71f739b367d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m115"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

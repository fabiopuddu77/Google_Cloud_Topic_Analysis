{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a0f8e7-4de2-4dab-8fed-9057941c0ba2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from obj_preprocessing import GCS_preprocessing\n",
    "from google.cloud import aiplatform as aip\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e42dd764-6413-4fd0-a192-01cc7f41f3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'gcp-ccai-auto-ml-contactcenter'\n",
    "REGION= \"europe-west3\"\n",
    "REPO_NAME = \"repo-demo3\"\n",
    "SERVICE_ACCOUNT = \"944308723981-compute@developer.gserviceaccount.com\"\n",
    "BUCKET = \"ccai-storage\"\n",
    "PIPELINE_NAME = \"automl_pipeline\"\n",
    "YAML_NAME = f\"{PIPELINE_NAME}.yml\"\n",
    "PIPELINE_ROOT = f\"gs://{BUCKET}/pipeline_root/\"\n",
    "DISPLAY_NAME = PIPELINE_NAME.replace(\"_\", \"-\")\n",
    "NOTEBOOK = \"automl\"\n",
    "DATANAME = \"datasetnlp\"\n",
    "FILE_PATH = 'test_file.parquet'\n",
    "FOLDER = 'make_prediction'\n",
    "PROJECT_ID = 'gcp-ccai-auto-ml-contactcenter'\n",
    "TABLE_ID = \"testdatabq\"\n",
    "TEXT_COLUMN = 'body_pre'\n",
    "LOCATION = \"europe-west3\"\n",
    "NUM_DOC = 20\n",
    "RANDOM_SEED=123\n",
    "#BQ_SOURCE = \"bq://gcp-ccai-auto-ml-contactcenter.datasetnlp.stepfinalbq\"\n",
    "\n",
    "OUTPUT_FINAL = 'step_final_bq.parquet'\n",
    "\n",
    "# Resources\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1de0ba70-d114-4a26-a2e6-293751f759fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Dataframe prediction\n",
      "Adapt the variables to the autoML\n",
      "Create instances\n"
     ]
    }
   ],
   "source": [
    "processor = GCS_preprocessing(bucket=BUCKET,\n",
    "                              folder=FOLDER,\n",
    "                              file_path=FILE_PATH,\n",
    "                              parquet_file_name=OUTPUT_FINAL,\n",
    "                              num_doc=NUM_DOC, \n",
    "                              random_seed=RANDOM_SEED,\n",
    "                              project_id=PROJECT_ID,\n",
    "                              dataset_id=DATANAME,\n",
    "                              table_id=TABLE_ID,\n",
    "                              location=LOCATION,\n",
    "                              text_column=TEXT_COLUMN,\n",
    "                              pipeline_root=PIPELINE_ROOT,\n",
    "                              overwrite=False)\n",
    "\n",
    "\n",
    "instances = processor.process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00dcc09d-5e84-4280-8a1f-b5401989fe75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDPOINTS: \n",
      "automl_datasetnlp_20240325224945\n",
      "\n",
      "PREDICTIONS\n",
      "+------------------------+------------+\n",
      "| Class                  |      Score |\n",
      "+========================+============+\n",
      "| Technology             | 0.00651041 |\n",
      "+------------------------+------------+\n",
      "| Sports                 | 0.928073   |\n",
      "+------------------------+------------+\n",
      "| Science                | 0.00101889 |\n",
      "+------------------------+------------+\n",
      "| Politics               | 0.0162563  |\n",
      "+------------------------+------------+\n",
      "| Health                 | 0.00204835 |\n",
      "+------------------------+------------+\n",
      "| Environment            | 0.00269876 |\n",
      "+------------------------+------------+\n",
      "| Business               | 0.0195512  |\n",
      "+------------------------+------------+\n",
      "| Arts and Entertainment | 0.0238427  |\n",
      "+------------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "aip.Endpoint.list(filter=f'labels.notebook={NOTEBOOK}')\n",
    "endpoint = aip.Endpoint.list(filter=f'labels.notebook={NOTEBOOK}')[0]\n",
    "print(f\"ENDPOINTS: \\n{endpoint.display_name}\\n\")\n",
    "prediction = endpoint.predict(instances = instances) # or instances = newobs\n",
    "\n",
    "dictionary=prediction.predictions[2]\n",
    "# Convert the dictionary into a list of tuples\n",
    "table_data = list(zip(dictionary['classes'], dictionary['scores']))\n",
    "\n",
    "# Print the table\n",
    "print(\"PREDICTIONS\")\n",
    "print(tabulate(table_data, headers=['Class', 'Score'], tablefmt='grid'))\n",
    "#print(f\"PREDICTIONS: \\n {prediction.predictions[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55330309-1bbe-4d98-86db-1c7861c7f135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m115"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
